{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I used ChatGPT to provide me with these problem statements so that I can practise Optimization techniques implementation from the basics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hOiJAjpnklhJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyYMNU-bmZXl"
   },
   "source": [
    "Problem 1: **Gradient Descent for Demand Forecasting**\n",
    "\n",
    "I want to optimize the prediction of regional product demands using gradient descent.\n",
    "\n",
    "Assume the loss function is\n",
    "\n",
    "$$L(w)=(w‚àí4)^2$$\n",
    "\n",
    "where **w** is a weight parameter initialized at 0.\n",
    "\n",
    "\n",
    "* Perform 10 iterations of gradient descent using a learning rate of 0.1.\n",
    "\n",
    "* Print the weight **w** at each step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bhYyNy9mndvd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: w = 0.8000\n",
      "Step 2: w = 1.4400\n",
      "Step 3: w = 1.9520\n",
      "Step 4: w = 2.3616\n",
      "Step 5: w = 2.6893\n",
      "Step 6: w = 2.9514\n",
      "Step 7: w = 3.1611\n",
      "Step 8: w = 3.3289\n",
      "Step 9: w = 3.4631\n",
      "Step 10: w = 3.5705\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "w = 0.0\n",
    "\n",
    "for i in range (10):\n",
    "  gradient = 2*(w-4)\n",
    "  w -= learning_rate*gradient\n",
    "  print(f\"Step {i+1}: w = {w:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xADdX0ULpDhP"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40THnZYtoOkV"
   },
   "source": [
    "\n",
    "\n",
    "$$f(x,y)=x^2 +3y^2$$\n",
    "\n",
    "Write a code to implement gradient descent (5 iterations) with momentum to minimize this function.\n",
    "\n",
    "Use:\n",
    "* Initial point (x, y) = (2, 2)\n",
    "* Learning rate (Œ∑) = 0.1\n",
    "* Momentum Coefficient (Œ≤)) = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z2wHwhiHpCwf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: x = 1.9600, y = 1.8800\n",
      "Step 2: x = 1.8848, y = 1.6592\n",
      "Step 3: x = 1.7794, y = 1.3609\n",
      "Step 4: x = 1.6490, y = 1.0108\n",
      "Step 5: x = 1.4986, y = 0.6351\n"
     ]
    }
   ],
   "source": [
    "def gradient(x, y):\n",
    "  return 2*x,6*y\n",
    "\n",
    "x, y =2,2\n",
    "learning_rate =0.1\n",
    "momentum =0.9\n",
    "vx, vy = 0.0, 0.0 # initialized velocity\n",
    "\n",
    "for i in range(5):\n",
    "  dx, dy = gradient(x, y)\n",
    "  vx = momentum*vx+(1-momentum)*dx\n",
    "  vy = momentum*vy+(1-momentum)*dy\n",
    "  x -= learning_rate*vx\n",
    "  y -= learning_rate*vy\n",
    "  print(f\"Step {i+1}: x = {x:.4f}, y = {y:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2tQRlsUqLvx"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJjaxm6kqNKE"
   },
   "source": [
    "\n",
    "\n",
    "$$f(w) = w^2 + 5$$\n",
    "\n",
    "Use:\n",
    "\n",
    "* Initial weight (ùë§) = 5.0\n",
    "* Learning rate (Œ∑) = 0.01\n",
    "* Momentum Coefficient(Œ≤)=0.9\n",
    "\n",
    "\n",
    "Run the optimization for 15 iterations and print the weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4GjcPpNKrwzm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: w = 4.9684\n",
      "Step 2: w = 4.9455\n",
      "Step 3: w = 4.9264\n",
      "Step 4: w = 4.9094\n",
      "Step 5: w = 4.8939\n",
      "Step 6: w = 4.8794\n",
      "Step 7: w = 4.8657\n",
      "Step 8: w = 4.8526\n",
      "Step 9: w = 4.8400\n",
      "Step 10: w = 4.8277\n",
      "Step 11: w = 4.8158\n",
      "Step 12: w = 4.8041\n",
      "Step 13: w = 4.7927\n",
      "Step 14: w = 4.7814\n",
      "Step 15: w = 4.7704\n"
     ]
    }
   ],
   "source": [
    "def gradient(w):\n",
    "  return 2*w\n",
    "\n",
    "w =5.0\n",
    "learning_rate =0.01\n",
    "beta =0.9\n",
    "epsilon = 1e-8\n",
    "squared_gradient_average = 0.0 # initialized squared gradient average\n",
    "\n",
    "for i in range(15):\n",
    "  grad = gradient(w)\n",
    "  squared_gradient_average = beta*squared_gradient_average+(1-beta)*(grad**2)\n",
    "  w -=learning_rate*grad/((squared_gradient_average+epsilon)**(1/2)) \n",
    "  print(f\"Step {i+1}: w = {w:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0tb736Ysolc"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87npAc9ysqOU"
   },
   "source": [
    "\n",
    "\n",
    "$$f(x) = x^4 - 3x^3 + 2$$\n",
    "\n",
    "Write code to:\n",
    "\n",
    "* Initialize x = 3.0\n",
    "\n",
    "Run the optimizations for 19 iterations (starting from 1) with:\n",
    "* Learning rate (Œ∑) = 0.01\n",
    "* Momentum Coefficients: Œ≤1 = 0.9, Œ≤2 = 0.09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dQjK7sR4twzm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: x = 2.9900\n",
      "Step 2: x = 2.9799\n",
      "Step 3: x = 2.9697\n",
      "Step 4: x = 2.9595\n",
      "Step 5: x = 2.9491\n",
      "Step 6: x = 2.9387\n",
      "Step 7: x = 2.9281\n",
      "Step 8: x = 2.9174\n",
      "Step 9: x = 2.9067\n",
      "Step 10: x = 2.8958\n",
      "Step 11: x = 2.8849\n",
      "Step 12: x = 2.8739\n",
      "Step 13: x = 2.8627\n",
      "Step 14: x = 2.8515\n",
      "Step 15: x = 2.8401\n",
      "Step 16: x = 2.8287\n",
      "Step 17: x = 2.8171\n",
      "Step 18: x = 2.8054\n",
      "Step 19: x = 2.7937\n"
     ]
    }
   ],
   "source": [
    "def gradient(x):\n",
    "  return 4*x**3-9*x**2\n",
    "\n",
    "x =3.0\n",
    "learning_rate =0.01\n",
    "beta1, beta2 =0.9,0.09\n",
    "epsilon =1e-8\n",
    "first_moment, second_moment = 0.0, 0.0 # initialized first and second moment\n",
    "\n",
    "for t in range(1, 20):\n",
    "  grad = gradient(x)\n",
    "  m = beta1*first_moment+(1-beta1)*grad\n",
    "  v = beta2*second_moment+(1-beta2)*(grad**2)\n",
    "  m_hat = m/(1-beta1**t)\n",
    "  v_hat = v/(1-beta2**t)\n",
    "  x -=learning_rate*m_hat/((v_hat+epsilon)**(1/2)) \n",
    "  first_moment, second_moment = m, v\n",
    "  print(f\"Step {t}: x = {x:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "953S3HD64qNm"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
